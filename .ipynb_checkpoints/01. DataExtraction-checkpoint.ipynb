{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Wrangling & Other General Use\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "# For scrapping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import urllib\n",
    "from urllib import parse\n",
    "\n",
    "\n",
    "# For debugging\n",
    "from icecream import ic\n",
    "ic.configureOutput(prefix = 'Debug | ')\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Gathering the page full HTML code (w/ Selenium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_url(keywords_in, location_in):\n",
    "    \"\"\"Pass the parameters to an url parser\"\"\"\n",
    "    querystring = 'search?' + parse.urlencode({'keywords': keywords_in, 'location': location_in, 'position': 1, 'pageNum': 0})\n",
    "    url = 'https://www.linkedin.com/jobs/' + querystring\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_full_html(url):\n",
    "    \"\"\"Gathering the page full HTML code (w/ Selenium)\"\"\"\n",
    "    \n",
    "    driver_path = 'C:\\Program Files (x86)\\chromedriver.exe'\n",
    "    driver = webdriver.Chrome(driver_path)\n",
    "    driver.get(url)\n",
    "\n",
    "    # Get the number of jobs the page shows on top of the cards\n",
    "    soup = BeautifulSoup(driver.page_source)\n",
    "    \n",
    "    try:\n",
    "        nr_jobs = soup.find('span', class_ = 'results-context-header__job-count').text.strip()\n",
    "        print(f'\\nTotal Number of Jobs Advertised in the Top: {nr_jobs}\\n')\n",
    "\n",
    "        nr_jobs_initial = get_jobs_loaded(driver)\n",
    "        print('Number of Jobs Loaded in the Browser:')\n",
    "        print(f'  @ Opening Page: {nr_jobs_initial}')\n",
    "\n",
    "        scrolls = 0\n",
    "        buttons = 0\n",
    "\n",
    "        while soup.find('div', class_ = 'inline-notification see-more-jobs__viewed-all') is None:\n",
    "            # Stop when a \"You've viewed all jobs\" card appears\n",
    "\n",
    "            nr_jobs_loaded_init = get_jobs_loaded(driver)\n",
    "\n",
    "            try:\n",
    "                # Click the \"Show More Jobs\" button\n",
    "                driver.find_element_by_xpath(\"//button[@class='infinite-scroller__show-more-button infinite-scroller__show-more-button--visible']\").click()\n",
    "                buttons += 1\n",
    "                buttons_print = 'Button' if buttons == 1 else 'Buttons'\n",
    "\n",
    "                # Give the browser some time to fetch the results\n",
    "                time.sleep(1)\n",
    "\n",
    "                # Printing the number of jobs already loaded\n",
    "                nr_jobs_loaded = get_jobs_loaded(driver)\n",
    "                if nr_jobs_loaded != nr_jobs_loaded_init:\n",
    "                    print(f'  After {buttons} {buttons_print}: {nr_jobs_loaded}')\n",
    "\n",
    "            except:\n",
    "                # Scroll through the infinite scroll until the \"Show More Jobs\" button appears\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                scrolls += 1\n",
    "                scrolls_print = 'Scroll' if scrolls == 1 else 'Scrolls'\n",
    "\n",
    "                time.sleep(1.2)\n",
    "                nr_jobs_loaded = get_jobs_loaded(driver)\n",
    "                if nr_jobs_loaded != nr_jobs_loaded_init:\n",
    "                    print(f'  After {scrolls} {scrolls_print}: {nr_jobs_loaded}')\n",
    "\n",
    "\n",
    "            # Refreshing the soup for assessment in the while loop condition\n",
    "            soup = BeautifulSoup(driver.page_source)\n",
    "\n",
    "        # Closing the browser\n",
    "        print(\"\\nBrowser is now closed.\")\n",
    "        driver.close()\n",
    "    \n",
    "    except:\n",
    "        print('Linkedin is blocking the crawling. Wait some more and try again.')\n",
    "    \n",
    "    return soup\n",
    "\n",
    "\n",
    "def get_jobs_loaded(driver):\n",
    "    soup_jobs = BeautifulSoup(driver.page_source)\n",
    "    nr_jobs = len(soup_jobs.find('ul', class_ = 'jobs-search__results-list').find_all('li'))\n",
    "    return nr_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Gathering all information from the job cards (w/ BeautifulSoup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_job_card_info(soup):\n",
    "    \"\"\"Gathering all information from the job cards (w/ BeautifulSoup)\"\"\"\n",
    "    \n",
    "    jobs_card = soup.find('ul', class_ = 'jobs-search__results-list')\n",
    "\n",
    "    jobs = []\n",
    "\n",
    "    for li in jobs_card.find_all('li'):\n",
    "        full_details_url = li.find('a').get('href').replace('https://pt.linkedin', 'https://linkedin')\n",
    "        position = li.find('h3', class_ = 'base-search-card__title').text.strip()\n",
    "        company = li.find('h4', class_ = 'base-search-card__subtitle').text.strip()\n",
    "        metadata = li.find('div', class_ = 'base-search-card__metadata')\n",
    "        location = metadata.find('span', class_ = 'job-search-card__location').text.strip()\n",
    "        posting_date = metadata.find('time').get('datetime')\n",
    "\n",
    "        job_info = {'Company': company,\n",
    "                    'Location': location,\n",
    "                    'Position': position,\n",
    "                    'PostingDate': posting_date,\n",
    "                    'FullDetailsURL': full_details_url[:full_details_url.find('?refId=')]}\n",
    "\n",
    "        if job_info not in jobs:\n",
    "            jobs.append(job_info)\n",
    "\n",
    "    df_extr = pd.DataFrame(jobs)\n",
    "\n",
    "    print(f\"\\nAll {len(jobs)} jobs' information is now loaded to a dataframe.\\n\")\n",
    "    \n",
    "    return df_extr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Gathering Full Job Info through the URL's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_full_info(df_extr):\n",
    "\n",
    "    try:\n",
    "        # Reading previous days info from csv file\n",
    "        df_full = pd.read_csv('FullInfoDataframe.csv') \n",
    "    except:\n",
    "        # First instance of the dataframe \n",
    "        df_full = pd.DataFrame(columns = ['ResultsDate', 'Company', 'Location', 'Position', 'PostingDate', 'FullDetailsURL', 'AllQualifications', 'Office', 'Applicants'])\n",
    "        df_full.to_csv('FullInfoDataframe.csv',\n",
    "                       index = False)\n",
    "\n",
    "    print('Fetching results:\\n')\n",
    "    print('JobID | JobTitle | Company | Location')\n",
    "\n",
    "    for i in range(len(df_extr)):\n",
    "\n",
    "        if df_extr['FullDetailsURL'][i] not in df_full['FullDetailsURL'].unique():\n",
    "\n",
    "            job_info = df_extr.iloc[i].to_dict()\n",
    "            # Save the process datetime (day & hour)\n",
    "            job_info['ResultsDate'] = datetime.now().strftime(\"%d/%m/%Y %H\")\n",
    "\n",
    "            print(i, '|', df_extr['Position'][i], '|', df_extr['Company'], '|', df_extr['Location'][i])\n",
    "\n",
    "            job_url = df_extr['FullDetailsURL'][i]\n",
    "\n",
    "            job_page = requests.get(job_url, headers)\n",
    "            soup = BeautifulSoup(job_page.content)\n",
    "\n",
    "            try:\n",
    "                # if full_description returns None, we know Linkedin blocked the request\n",
    "                full_description = soup.find('div', class_ = 'show-more-less-html__markup')\n",
    "\n",
    "                try:\n",
    "                    # Store required qualifications in a list\n",
    "                    qualifications = []\n",
    "                    for qualification in full_description.find_all('li'):\n",
    "                        qualification = qualification.text\n",
    "                        qualifications.append(qualification)\n",
    "\n",
    "                    job_info['AllQualifications'] = qualifications\n",
    "\n",
    "                    try:\n",
    "                        # Store the office indications (some jobs actually have different offices in the description)\n",
    "                        pointer = 'You will be based in our'\n",
    "                        pointer_pos = full_description.text.find(pointer)\n",
    "                        if pointer_pos != -1:\n",
    "                            office_st = full_description.text[full_description.text.find(pointer) + len(pointer):]\n",
    "                            office = office_st[:office_st.find('office')].strip()\n",
    "                            # Sometimes the description is customized and 'office' won't appear\n",
    "                            if len(office) > 100:\n",
    "                                office = office_st[:office_st.find('.')].strip()\n",
    "                        else:\n",
    "                            office = ''\n",
    "\n",
    "                        job_info['Office'] = office\n",
    "\n",
    "                        try:\n",
    "                            # Job Criteria List (Employment Type, Industries, Job Function, Seniority Level)\n",
    "                            criteria = soup.find('ul', class_ = 'description__job-criteria-list')\n",
    "                            criteria_boxes = soup.find_all('li', class_ = 'description__job-criteria-item')\n",
    "                            criteria_list = []\n",
    "                            for box in criteria_boxes:\n",
    "                                criteria_header = box.find('h3').text.strip()\n",
    "                                criteria_text = box.find('span').text.strip()\n",
    "\n",
    "                                job_info[criteria_header] = criteria_text\n",
    "\n",
    "                            try:\n",
    "                                # Get the info regarding current applicants\n",
    "                                # If we were logged into Linkedin, we would have the exact number for those jobs under 25 applicants\n",
    "                                try:\n",
    "                                    job_info['Applicants'] = soup.find('span', class_ = 'num-applicants__caption topcard__flavor--metadata topcard__flavor--bullet') \\\n",
    "                                                                 .text.strip()\n",
    "                                except:\n",
    "                                    job_info['Applicants'] = soup.find('figure', class_ = 'num-applicants__figure topcard__flavor--metadata topcard__flavor--bullet') \\\n",
    "                                                                 .text.strip()\n",
    "\n",
    "                            except:\n",
    "                                print('  Errors occurred when parsing job \"Applicants\"')\n",
    "                        except:\n",
    "                            print('  Errors occurred when parsing job \"Criteria\"')\n",
    "                    except:\n",
    "                        print('  Errors occurred when parsing job \"Office\"')\n",
    "                except:\n",
    "                    print('  Errors occurred when parsing job \"Qualifications\"')\n",
    "\n",
    "            except:\n",
    "                raise ValueError('LINKEDIN BLOCKED THE REQUEST')\n",
    "\n",
    "            # Add the job dict to the dataframe\n",
    "            df_full = df_full.append(job_info, ignore_index = True)\n",
    "\n",
    "        time.sleep(random.random() * 3 + 1) # Waiting a randomized amount of time (higher than 1 and lower than 4 secs)\n",
    "\n",
    "    df_full.to_csv('FullInfoDataframe.csv',\n",
    "                   index = False)\n",
    "\n",
    "    print('\\nNumber of Jobs:', len(df_full['FullDetailsURL'].unique()))\n",
    "    print()\n",
    "    \n",
    "    return df_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the whole process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUTS -------------------------------------------------------\n",
    "# Select the company or the job you want to find results for\n",
    "keywords_in = '\"Data Scientist\"'\n",
    "# Select the location for it\n",
    "location_in = 'Lisbon'\n",
    "# --------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Number of Jobs Advertised in the Top: 112\n",
      "\n",
      "Number of Jobs Loaded in the Browser:\n",
      "  @ Opening Page: 23\n",
      "  After 1 Scroll: 47\n",
      "  After 2 Scrolls: 72\n",
      "  After 3 Scrolls: 97\n",
      "  After 4 Scrolls: 108\n",
      "\n",
      "Browser is now closed.\n"
     ]
    }
   ],
   "source": [
    "# STAGE 1\n",
    "soup = gather_full_html(build_url(keywords_in, location_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All 108 jobs' information is now loaded to a dataframe.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Position</th>\n",
       "      <th>PostingDate</th>\n",
       "      <th>FullDetailsURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>McKinsey &amp; Company</td>\n",
       "      <td>Lisbon, Lisbon, Portugal</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>2021-07-17</td>\n",
       "      <td>https://linkedin.com/jobs/view/data-scientist-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Siemens</td>\n",
       "      <td>Lisbon, Lisbon, Portugal</td>\n",
       "      <td>Data Scientist (m/f/d)</td>\n",
       "      <td>2021-07-03</td>\n",
       "      <td>https://linkedin.com/jobs/view/data-scientist-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Siemens</td>\n",
       "      <td>Lisbon, Lisbon, Portugal</td>\n",
       "      <td>Junior Data Scientist (m/f/d)</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>https://linkedin.com/jobs/view/junior-data-sci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NOS SGPS</td>\n",
       "      <td>Lisbon, Portugal</td>\n",
       "      <td>Data Scientist - Lisboa ou Porto</td>\n",
       "      <td>2021-07-27</td>\n",
       "      <td>https://linkedin.com/jobs/view/data-scientist-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Winning</td>\n",
       "      <td>Lisbon, Lisbon, Portugal</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>2021-07-26</td>\n",
       "      <td>https://linkedin.com/jobs/view/data-scientist-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Company                  Location  \\\n",
       "0  McKinsey & Company  Lisbon, Lisbon, Portugal   \n",
       "1             Siemens  Lisbon, Lisbon, Portugal   \n",
       "2             Siemens  Lisbon, Lisbon, Portugal   \n",
       "3            NOS SGPS          Lisbon, Portugal   \n",
       "4             Winning  Lisbon, Lisbon, Portugal   \n",
       "\n",
       "                           Position PostingDate  \\\n",
       "0                    Data Scientist  2021-07-17   \n",
       "1            Data Scientist (m/f/d)  2021-07-03   \n",
       "2     Junior Data Scientist (m/f/d)  2021-07-01   \n",
       "3  Data Scientist - Lisboa ou Porto  2021-07-27   \n",
       "4                    Data Scientist  2021-07-26   \n",
       "\n",
       "                                      FullDetailsURL  \n",
       "0  https://linkedin.com/jobs/view/data-scientist-...  \n",
       "1  https://linkedin.com/jobs/view/data-scientist-...  \n",
       "2  https://linkedin.com/jobs/view/junior-data-sci...  \n",
       "3  https://linkedin.com/jobs/view/data-scientist-...  \n",
       "4  https://linkedin.com/jobs/view/data-scientist-...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STAGE 2\n",
    "df_extr = gather_job_card_info(soup)\n",
    "df_extr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching results:\n",
      "\n",
      "JobID | JobTitle | Location\n",
      "0 | Data Scientist | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "1 | Data Scientist (m/f/d) | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "2 | Junior Data Scientist (m/f/d) | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "3 | Data Scientist - Lisboa ou Porto | Lisbon, Portugal\n",
      "  Success.\n",
      "4 | Data Scientist | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "5 | Product Data Scientist | Lisbon, Portugal\n",
      "  Success.\n",
      "6 | Data Scientist | Lisboa, Lisbon, Portugal\n",
      "  Success.\n",
      "7 | Senior Data Scientist (Lisbon) | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "8 | Data Scientist | Lisbon, Portugal\n",
      "  Success.\n",
      "9 | Junior Data Scientist | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "10 | Data Scientist (m/f) | Lisbon, Portugal\n",
      "  Success.\n",
      "11 | Data Scientist – Scoring Centre (M/F) | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "12 | Quantitative Research - Data Scientist | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "13 | Junior Data Scientist – Scoring Centre (M/F) | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "14 | Data Scientist | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "15 | Data Scientist | Lisbon, Portugal\n",
      "  Success.\n",
      "16 | Data scientist / Risk Data Analyst Trainee | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "17 | Junior Data Scientist - Scoring Centre | Lisbon, Portugal\n",
      "  Success.\n",
      "18 | Senior Data Scientist | Lisbon, Portugal\n",
      "  Success.\n",
      "19 | Data Manager/Data Scientist (M/F) | Lisbon, Portugal\n",
      "  Success.\n",
      "20 | Data Scientist | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "21 | Data Scientist (B) [604] | Lisboa, Lisbon, Portugal\n",
      "  Success.\n",
      "22 | Data Scientist (m/f) | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "23 | Data Scientist – AI & ML (M/F) Lisboa | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "24 | Data Scientist (M/F) - Lisbon | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "25 | Data Scientist | Carnaxide, Lisbon, Portugal\n",
      "  Success.\n",
      "26 | Data Scientist (Nearshore Project in Lisbon) | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "27 | Sr. Data Scientist - Bot Management | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "28 | Risk Data Analyst / Data Scientist | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "29 | Data Scientist (Traineeship) | Amadora, Lisbon, Portugal\n",
      "  Success.\n",
      "30 | Data Scientist | Lisboa, Lisbon, Portugal\n",
      "  Success.\n",
      "31 | Data Scientist (m/f) | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "32 | CUSTOMER INTELLIGENCE ANALYST – Data Scientist – Lisbon | Lisbon, Portugal\n",
      "  Success.\n",
      "33 | Data Scientist | Lisbon, Portugal\n",
      "  Success.\n",
      "34 | Data Scientist (m/f) | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "35 | Data Scientist | Lisbon, Lisbon, Portugal\n",
      "  Errors occurred when parsing job \"Applicants\"\n",
      "36 | Data Scientist [A] | Lisboa, Lisbon, Portugal\n",
      "  Success.\n",
      "37 | Senior Data Scientist | Lisbon, Portugal\n",
      "  Success.\n",
      "38 | Data Scientist | Lisboa, Lisbon, Portugal\n",
      "  Errors occurred when parsing job \"Applicants\"\n",
      "39 | Senior Data Scientist (Computer Vision/Machine Learning) | Lisbon, Portugal\n",
      "  Success.\n",
      "40 | Data Scientist - m/f | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "41 | Data Scientist | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "42 | Data Scientist [A] (356) | Lisboa, Lisbon, Portugal\n",
      "  Success.\n",
      "43 | Senior Data Scientist – Scoring Centre (M/F) | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "44 | Data Manager/Data Scientist (M/F) | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "45 | Data Scientist (A) [621] | Lisboa, Lisbon, Portugal\n",
      "  Success.\n",
      "46 | Data scientist | Lisbon, Portugal\n",
      "  Success.\n",
      "47 | Senior Data Scientist / Engineer - Stress Testing and Data Analytics | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "48 | Data Scientist | Lisbon, Portugal\n",
      "  Errors occurred when parsing job \"Applicants\"\n",
      "49 | Data Scientist - Customer Analytics | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "50 | Data Scientist | Lisbon, Portugal\n",
      "  Success.\n",
      "51 | Data Scientist | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "52 | Consultant, Analytics, Data and Services | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "53 | Sr Data Scientist | Amadora, Lisbon, Portugal\n",
      "  Success.\n",
      "54 | Data Scientist (m/f) | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "55 | Data Scientist (B) [604] | Lisboa, Lisbon, Portugal\n",
      "  Success.\n",
      "56 | Senior Data Scientist | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "57 | Data Scientist (A) [621] | Lisboa, Lisbon, Portugal\n",
      "  Success.\n",
      "58 | Senior Data Scientist (m/f) | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "59 | Data Scientist | Lisbon, Lisbon, Portugal\n",
      "  Errors occurred when parsing job \"Applicants\"\n",
      "60 | Senior Data Scientist Consultant with Python | Lisbon, Portugal\n",
      "  Success.\n",
      "61 | Data Scientist - Machine Learning & NLP | Lisboa, Lisbon, Portugal\n",
      "  Success.\n",
      "62 | SMART DATA SCIENTIST | Lisboa | Lisboa, Lisbon, Portugal\n",
      "  Success.\n",
      "63 | Data Scientist (m/f) | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "64 | Senior Data Scientist | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "65 | Senior Data Scientist Consultant & Data Lover | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "66 | Data Scientist (m/f) | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "67 | Data Scientist em NLP | Lisboa, Lisbon, Portugal\n",
      "  Success.\n",
      "68 | Data Scientist (m/f) ? Lisboa | Lisboa, Lisbon, Portugal\n",
      "  Success.\n",
      "69 | Anúncio de emprego: Data Scientist (M/F) | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "70 | Data Science & NLP | Lisboa, Lisbon, Portugal\n",
      "  Success.\n",
      "71 | Anúncio de emprego: Data Scientist | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "72 | Oferta de emprego: Data Scientist | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "73 | Oferta de emprego: Data scientist for International Institution | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "74 | Anúncio de emprego: Senior Data Scientist | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "75 | Oferta de trabalho Data Scientist (M/F) | Lisboa, Lisbon, Portugal\n",
      "  Success.\n",
      "76 | Oferta de emprego: Data Scientist | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "77 | Data Scientist (French) (m/f) | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "78 | Consultor Data Scientist Machine Learning (m/f) | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "79 | Capacity Planning Analyst | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "80 | Oferta de emprego: Consultor Data Scientist (m/f) | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "81 | Anúncio de emprego: Data Scientist(S) | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "82 | Lead Consultant, Analytics, Data and Services | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "83 | Oferta de trabalho Data Scientist (SAS E-Miner) (F/M) | Lisboa, Lisbon, Portugal\n",
      "  Success.\n",
      "84 | Anúncio de emprego: Data Scientist (SAS E-Miner) (F/M) | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "85 | BI Consultant (m/f) | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "86 | Oferta de emprego: Data Scientist (m/f) – Lisboa | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "87 | New Grads - PT Remote | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "88 | Model Risk Manager | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "89 | Data Scientist – Remote, Full-time | Amadora, Lisbon, Portugal\n",
      "  Success.\n",
      "90 | Anúncio de emprego: Data Science- Lisboa | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "91 | Anúncio de emprego: Senior Data Scientist (m/f) – Lisboa | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "92 | IBM Associates Business Transformation Consultant | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "93 | Data Scientist – Remote, Full-time | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "94 | Capacity Planning Program Manager | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "95 | Capacity Planning Engineer | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "96 | Epidemiologist | Lisboa, Lisbon, Portugal\n",
      "  Success.\n",
      "97 | Senior Data Engineer | Amadora, Lisbon, Portugal\n",
      "  Success.\n",
      "98 | Data Scientist Intern (m/f/d) | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "99 | Business Intelligence Developer | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "100 | Anúncio de emprego: Machine Learning Engineer (m/f) - Nearshore | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "101 | Senior Python Data Engineer (m/f) | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "102 | Real World Data Senior Biostatistician | Lisboa, Lisbon, Portugal\n",
      "  Success.\n",
      "103 | Real World Data Senior Biostatistician | Lisboa, Lisbon, Portugal\n",
      "  Success.\n",
      "104 | Senior Data Engineer | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "105 | Senior Product Designer - AI | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "106 | Procurement Intelligence SAP BW Specialist | Amadora, Lisbon, Portugal\n",
      "  Success.\n",
      "107 | Data Engineer - m/f | Lisbon, Lisbon, Portugal\n",
      "  Success.\n",
      "\n",
      "Number of Jobs: 108\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Position</th>\n",
       "      <th>PostingDate</th>\n",
       "      <th>FullDetailsURL</th>\n",
       "      <th>AllQualifications</th>\n",
       "      <th>Office</th>\n",
       "      <th>Applicants</th>\n",
       "      <th>Employment type</th>\n",
       "      <th>Industries</th>\n",
       "      <th>Job function</th>\n",
       "      <th>ResultsDate</th>\n",
       "      <th>Seniority level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>McKinsey &amp; Company</td>\n",
       "      <td>Lisbon, Lisbon, Portugal</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>2021-07-17</td>\n",
       "      <td>https://linkedin.com/jobs/view/data-scientist-...</td>\n",
       "      <td>[Master’s degree in a quantitative field like ...</td>\n",
       "      <td>Client Capability Hub in our Lisbon or Wroclaw</td>\n",
       "      <td>39 applicants</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Automotive, Aviation &amp; Aerospace, and Manageme...</td>\n",
       "      <td>Consulting, Information Technology, and Marketing</td>\n",
       "      <td>27/07/2021 12</td>\n",
       "      <td>Associate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Siemens</td>\n",
       "      <td>Lisbon, Lisbon, Portugal</td>\n",
       "      <td>Data Scientist (m/f/d)</td>\n",
       "      <td>2021-07-03</td>\n",
       "      <td>https://linkedin.com/jobs/view/data-scientist-...</td>\n",
       "      <td>[Work with large, complex data sets and applyi...</td>\n",
       "      <td></td>\n",
       "      <td>Be among the first 25 applicants</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Electrical/Electronic Manufacturing</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>27/07/2021 12</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Siemens</td>\n",
       "      <td>Lisbon, Lisbon, Portugal</td>\n",
       "      <td>Junior Data Scientist (m/f/d)</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>https://linkedin.com/jobs/view/junior-data-sci...</td>\n",
       "      <td>[Build predictive and machine learning models ...</td>\n",
       "      <td></td>\n",
       "      <td>Be among the first 25 applicants</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Electrical/Electronic Manufacturing</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>27/07/2021 12</td>\n",
       "      <td>Associate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Company                  Location  \\\n",
       "0  McKinsey & Company  Lisbon, Lisbon, Portugal   \n",
       "1             Siemens  Lisbon, Lisbon, Portugal   \n",
       "2             Siemens  Lisbon, Lisbon, Portugal   \n",
       "\n",
       "                        Position PostingDate  \\\n",
       "0                 Data Scientist  2021-07-17   \n",
       "1         Data Scientist (m/f/d)  2021-07-03   \n",
       "2  Junior Data Scientist (m/f/d)  2021-07-01   \n",
       "\n",
       "                                      FullDetailsURL  \\\n",
       "0  https://linkedin.com/jobs/view/data-scientist-...   \n",
       "1  https://linkedin.com/jobs/view/data-scientist-...   \n",
       "2  https://linkedin.com/jobs/view/junior-data-sci...   \n",
       "\n",
       "                                   AllQualifications  \\\n",
       "0  [Master’s degree in a quantitative field like ...   \n",
       "1  [Work with large, complex data sets and applyi...   \n",
       "2  [Build predictive and machine learning models ...   \n",
       "\n",
       "                                           Office  \\\n",
       "0  Client Capability Hub in our Lisbon or Wroclaw   \n",
       "1                                                   \n",
       "2                                                   \n",
       "\n",
       "                         Applicants Employment type  \\\n",
       "0                     39 applicants       Full-time   \n",
       "1  Be among the first 25 applicants       Full-time   \n",
       "2  Be among the first 25 applicants       Full-time   \n",
       "\n",
       "                                          Industries  \\\n",
       "0  Automotive, Aviation & Aerospace, and Manageme...   \n",
       "1                Electrical/Electronic Manufacturing   \n",
       "2                Electrical/Electronic Manufacturing   \n",
       "\n",
       "                                        Job function    ResultsDate  \\\n",
       "0  Consulting, Information Technology, and Marketing  27/07/2021 12   \n",
       "1                             Information Technology  27/07/2021 12   \n",
       "2                             Information Technology  27/07/2021 12   \n",
       "\n",
       "    Seniority level  \n",
       "0         Associate  \n",
       "1  Mid-Senior level  \n",
       "2         Associate  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STAGE 3\n",
    "df_full = gather_full_info(df_extr)\n",
    "df_full.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO:\n",
    "1. Schedule job to run the script at least daily\n",
    "2. Write script 2 - Data Analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
